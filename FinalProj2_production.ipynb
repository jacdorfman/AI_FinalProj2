{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "babeef06",
   "metadata": {},
   "source": [
    "# Production stage: use files 0-6 for model traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1ddc7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_gathered_at_0.csv\t   data_gathered_at_3.csv  initial_training_data.csv\r\n",
      "data_gathered_at_1.csv\t   data_gathered_at_4.csv  test_data.csv\r\n",
      "data_gathered_at_2.csv\t   data_gathered_at_5.csv  validation_test_data.csv\r\n",
      "data_gathered_at_2_bk.csv  data_gathered_at_6.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls raw_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30402dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir accum_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68901f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp raw_data/initial_training_data.csv accum_data/accumulated_data.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "afea846d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accumulated_data.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls accum_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d515a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import RMSprop,Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "raw_data_path = 'raw_data/'\n",
    "accum_data_path = 'accum_data/'\n",
    "accum_file_name = accum_data_path+'accumulated_data.csv'\n",
    "\n",
    "def create_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
    "    model.add(MaxPool2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPool2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def prepare_data(data):\n",
    "    \"\"\" Prepare data for modeling \n",
    "        input: data frame with labels und pixel data\n",
    "        output: image and label array \"\"\"\n",
    "    \n",
    "    image_array = np.zeros(shape=(len(data), 48, 48))\n",
    "    image_label = np.array(list(map(int, data['Emotion'])))\n",
    "    \n",
    "    for i, row in enumerate(data.index):\n",
    "        image = np.fromstring(data.loc[row, 'Pixels'], dtype=int, sep=' ')\n",
    "        image = np.reshape(image, (48, 48))\n",
    "        image_array[i] = image\n",
    "        \n",
    "    return image_array, image_label\n",
    "\n",
    "\n",
    "def data_to_tf_data(df):\n",
    "    image_array, image_label = prepare_data(df)\n",
    "    images = image_array.reshape((image_array.shape[0], 48, 48, 1))\n",
    "    images = images.astype('float32')/255\n",
    "    labels = to_categorical(image_label)\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ebaffbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_accum_data(nmb):\n",
    "    accum_data = pd.read_csv(accum_file_name)\n",
    "    next_data_file = raw_data_path+'data_gathered_at_' + str(nmb)+'.csv'\n",
    "    add_data = pd.read_csv(next_data_file)\n",
    "    accum_data.append(add_data)\n",
    "    accum_data.to_csv(accum_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e69e4a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmb = 0\n",
    "add_to_accum_data(nmb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "524441cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "6/6 [==============================] - 4s 632ms/step - loss: 0.3372 - accuracy: 0.2430 - val_loss: 1.8610 - val_accuracy: 0.2449\n",
      "Epoch 2/12\n",
      "6/6 [==============================] - 3s 525ms/step - loss: 0.3116 - accuracy: 0.2835 - val_loss: 1.8795 - val_accuracy: 0.2449\n",
      "Epoch 3/12\n",
      "6/6 [==============================] - 3s 572ms/step - loss: 0.3044 - accuracy: 0.2835 - val_loss: 1.9381 - val_accuracy: 0.2449\n",
      "Epoch 4/12\n",
      "6/6 [==============================] - 3s 530ms/step - loss: 0.3079 - accuracy: 0.2835 - val_loss: 2.0681 - val_accuracy: 0.2449\n",
      "Epoch 5/12\n",
      "6/6 [==============================] - 3s 539ms/step - loss: 0.3021 - accuracy: 0.2835 - val_loss: 1.8856 - val_accuracy: 0.2449\n",
      "Epoch 6/12\n",
      "6/6 [==============================] - 3s 567ms/step - loss: 0.3068 - accuracy: 0.2648 - val_loss: 1.9238 - val_accuracy: 0.2508\n",
      "Epoch 7/12\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 0.3046 - accuracy: 0.2960 - val_loss: 1.8884 - val_accuracy: 0.2449\n",
      "Epoch 8/12\n",
      "6/6 [==============================] - 3s 542ms/step - loss: 0.2988 - accuracy: 0.2835 - val_loss: 1.9450 - val_accuracy: 0.2449\n",
      "Epoch 9/12\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 0.2926 - accuracy: 0.2835 - val_loss: 1.9117 - val_accuracy: 0.2449\n",
      "Epoch 10/12\n",
      "6/6 [==============================] - 3s 548ms/step - loss: 0.2936 - accuracy: 0.2835 - val_loss: 1.9236 - val_accuracy: 0.2449\n",
      "Epoch 11/12\n",
      "6/6 [==============================] - 3s 513ms/step - loss: 0.2944 - accuracy: 0.2835 - val_loss: 2.0018 - val_accuracy: 0.2449\n",
      "Epoch 12/12\n",
      "6/6 [==============================] - 3s 563ms/step - loss: 0.2997 - accuracy: 0.2835 - val_loss: 2.2062 - val_accuracy: 0.2449\n",
      "113/113 [==============================] - 3s 22ms/step - loss: 2.1878 - accuracy: 0.2494\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(accum_file_name)\n",
    "train_images, train_labels = data_to_tf_data(train)\n",
    "\n",
    "val = pd.read_csv(raw_data_path+'validation_test_data.csv')\n",
    "val_images, val_labels = data_to_tf_data(val)\n",
    "\n",
    "\n",
    "model = create_model()\n",
    "class_weight = dict(zip(range(0, 7), (((train['Emotion'].value_counts()).sort_index())/len(train['Emotion'])).tolist()))\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    validation_data=(val_images, val_labels),\n",
    "                    class_weight = class_weight,\n",
    "                    epochs=12,\n",
    "                    batch_size=64)\n",
    "\n",
    "df = pd.read_csv(raw_data_path+'test_data.csv')\n",
    "test_images, test_labels = data_to_tf_data(df)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb15b61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: initial_model/assets\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model.save(\"initial_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b46ace26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding...                                                                       \n",
      "!\u001b[A\n",
      "  0%|          |Saving files                          0/4 [00:00<?,     ?file/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |.DwLC3VcarwAa9qLWXncsFf.tmp           0/1 [00:00<?,       ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |.jy4vXLkQkyT7MAaCqtteMF.tmp     0.00/164k [00:00<?,       ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |.ni5xkLCKaDc4tBnqiaPpTk.tmp    0.00/3.83M [00:00<?,       ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |.iHDTQ34QjeBTNqbrwrcBLS.tmp    0.00/2.72k [00:00<?,       ?it/s]\u001b[A\n",
      "100% Add|██████████████████████████████████████████████|1/1 [00:00,  2.25file/s]\u001b[A\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add initial_model.dvc\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc add initial_model/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99d0e5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
