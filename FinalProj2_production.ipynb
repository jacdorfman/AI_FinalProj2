{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfe0670e",
   "metadata": {},
   "source": [
    "# Production stage: use files 0-6 for model traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca3ca3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_gathered_at_0.csv\t   data_gathered_at_3.csv  initial_training_data.csv\r\n",
      "data_gathered_at_1.csv\t   data_gathered_at_4.csv  test_data.csv\r\n",
      "data_gathered_at_2.csv\t   data_gathered_at_5.csv  validation_test_data.csv\r\n",
      "data_gathered_at_2_bk.csv  data_gathered_at_6.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls raw_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0be994a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘accum_data’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir accum_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a549cd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp raw_data/initial_training_data.csv accum_data/accumulated_data.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8172f900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2620\r\n",
      "-rw-r--r-- 1 root root 2679360 May 30 12:42 accumulated_data.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l accum_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88d844ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import RMSprop,Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "raw_data_path = 'raw_data/'\n",
    "accum_data_path = 'accum_data/'\n",
    "accum_file_name = accum_data_path+'accumulated_data.csv'\n",
    "\n",
    "def create_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
    "    model.add(MaxPool2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPool2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def prepare_data(data):\n",
    "    \"\"\" Prepare data for modeling \n",
    "        input: data frame with labels und pixel data\n",
    "        output: image and label array \"\"\"\n",
    "    \n",
    "    image_array = np.zeros(shape=(len(data), 48, 48))\n",
    "    image_label = np.array(list(map(int, data['Emotion'])))\n",
    "    \n",
    "    for i, row in enumerate(data.index):\n",
    "        image = np.fromstring(data.loc[row, 'Pixels'], dtype=int, sep=' ')\n",
    "        image = np.reshape(image, (48, 48))\n",
    "        image_array[i] = image\n",
    "        \n",
    "    return image_array, image_label\n",
    "\n",
    "\n",
    "def data_to_tf_data(df):\n",
    "    image_array, image_label = prepare_data(df)\n",
    "    images = image_array.reshape((image_array.shape[0], 48, 48, 1))\n",
    "    images = images.astype('float32')/255\n",
    "    labels = to_categorical(image_label)\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7cef8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_accum_data(nmb):\n",
    "    accum_data = pd.read_csv(accum_file_name)\n",
    "    next_data_file = raw_data_path+'data_gathered_at_' + str(nmb)+'.csv'\n",
    "    add_data = pd.read_csv(next_data_file)\n",
    "    accum_data = accum_data.append(add_data, ignore_index = True)\n",
    "    accum_data.to_csv(accum_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a6aa7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmb = 0\n",
    "add_to_accum_data(nmb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab5c1de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "7/7 [==============================] - 4s 551ms/step - loss: 0.3106 - accuracy: 0.2633 - val_loss: 1.8926 - val_accuracy: 0.2449\n",
      "Epoch 2/12\n",
      "7/7 [==============================] - 3s 496ms/step - loss: 0.2972 - accuracy: 0.2826 - val_loss: 2.0590 - val_accuracy: 0.2449\n",
      "Epoch 3/12\n",
      "7/7 [==============================] - 3s 487ms/step - loss: 0.2952 - accuracy: 0.2826 - val_loss: 1.8531 - val_accuracy: 0.2449\n",
      "Epoch 4/12\n",
      "7/7 [==============================] - 3s 503ms/step - loss: 0.2943 - accuracy: 0.2826 - val_loss: 1.9506 - val_accuracy: 0.2449\n",
      "Epoch 5/12\n",
      "7/7 [==============================] - 3s 469ms/step - loss: 0.2898 - accuracy: 0.2826 - val_loss: 1.8896 - val_accuracy: 0.2449\n",
      "Epoch 6/12\n",
      "7/7 [==============================] - 3s 493ms/step - loss: 0.2887 - accuracy: 0.2826 - val_loss: 1.9448 - val_accuracy: 0.2449\n",
      "Epoch 7/12\n",
      "7/7 [==============================] - 4s 564ms/step - loss: 0.2873 - accuracy: 0.2826 - val_loss: 1.9205 - val_accuracy: 0.2449\n",
      "Epoch 8/12\n",
      "7/7 [==============================] - 3s 480ms/step - loss: 0.2864 - accuracy: 0.2826 - val_loss: 1.8790 - val_accuracy: 0.2449\n",
      "Epoch 9/12\n",
      "7/7 [==============================] - 3s 462ms/step - loss: 0.2840 - accuracy: 0.2826 - val_loss: 1.9633 - val_accuracy: 0.2449\n",
      "Epoch 10/12\n",
      "7/7 [==============================] - 3s 479ms/step - loss: 0.2791 - accuracy: 0.2826 - val_loss: 1.8588 - val_accuracy: 0.2449\n",
      "Epoch 11/12\n",
      "7/7 [==============================] - 3s 529ms/step - loss: 0.2754 - accuracy: 0.2826 - val_loss: 1.8890 - val_accuracy: 0.2446\n",
      "Epoch 12/12\n",
      "7/7 [==============================] - 3s 459ms/step - loss: 0.2705 - accuracy: 0.2802 - val_loss: 1.8959 - val_accuracy: 0.2449\n",
      "113/113 [==============================] - 3s 23ms/step - loss: 1.8930 - accuracy: 0.2494\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(accum_file_name)\n",
    "train_images, train_labels = data_to_tf_data(train)\n",
    "\n",
    "val = pd.read_csv(raw_data_path+'validation_test_data.csv')\n",
    "val_images, val_labels = data_to_tf_data(val)\n",
    "\n",
    "\n",
    "model = create_model()\n",
    "class_weight = dict(zip(range(0, 7), (((train['Emotion'].value_counts()).sort_index())/len(train['Emotion'])).tolist()))\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    validation_data=(val_images, val_labels),\n",
    "                    class_weight = class_weight,\n",
    "                    epochs=12,\n",
    "                    batch_size=64)\n",
    "\n",
    "df = pd.read_csv(raw_data_path+'test_data.csv')\n",
    "test_images, test_labels = data_to_tf_data(df)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34480337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Pixels</th>\n",
       "      <th>rand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>215 218 222 220 221 226 218 215 216 218 218 21...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>145 146 118 26 15 18 16 18 24 38 57 66 71 78 8...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2 3 4 9 9 10 9 10 12 17 20 21 22 22 19 17 15 1...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>38 42 35 25 51 33 32 20 29 47 40 28 42 56 61 7...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>32 26 37 68 99 112 117 121 123 126 129 135 141...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>409</td>\n",
       "      <td>5</td>\n",
       "      <td>252 255 254 236 149 149 123 110 106 89 71 65 6...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>410</td>\n",
       "      <td>6</td>\n",
       "      <td>16 16 13 22 40 49 63 66 61 42 29 56 57 89 109 ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>411</td>\n",
       "      <td>3</td>\n",
       "      <td>60 58 58 38 44 54 54 71 57 42 41 53 90 53 57 5...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>412</td>\n",
       "      <td>6</td>\n",
       "      <td>118 124 109 94 66 11 19 48 84 114 147 164 182 ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>413</td>\n",
       "      <td>4</td>\n",
       "      <td>129 134 150 159 133 124 127 118 128 165 180 14...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>414 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  Emotion                                             Pixels  \\\n",
       "0             0        0  215 218 222 220 221 226 218 215 216 218 218 21...   \n",
       "1             1        6  145 146 118 26 15 18 16 18 24 38 57 66 71 78 8...   \n",
       "2             2        4  2 3 4 9 9 10 9 10 12 17 20 21 22 22 19 17 15 1...   \n",
       "3             3        3  38 42 35 25 51 33 32 20 29 47 40 28 42 56 61 7...   \n",
       "4             4        2  32 26 37 68 99 112 117 121 123 126 129 135 141...   \n",
       "..          ...      ...                                                ...   \n",
       "409         409        5  252 255 254 236 149 149 123 110 106 89 71 65 6...   \n",
       "410         410        6  16 16 13 22 40 49 63 66 61 42 29 56 57 89 109 ...   \n",
       "411         411        3  60 58 58 38 44 54 54 71 57 42 41 53 90 53 57 5...   \n",
       "412         412        6  118 124 109 94 66 11 19 48 84 114 147 164 182 ...   \n",
       "413         413        4  129 134 150 159 133 124 127 118 128 165 180 14...   \n",
       "\n",
       "     rand  \n",
       "0     7.0  \n",
       "1     8.0  \n",
       "2     9.0  \n",
       "3     8.0  \n",
       "4     7.0  \n",
       "..    ...  \n",
       "409   NaN  \n",
       "410   NaN  \n",
       "411   NaN  \n",
       "412   NaN  \n",
       "413   NaN  \n",
       "\n",
       "[414 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1c4a7807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: initial_model/assets\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model.save(\"initial_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0a2c09af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding...                                                                       \n",
      "!\u001b[A\n",
      "Computing file/dir hashes (only done once)            |0.00 [00:00,      ?md5/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "                                                      |0.00 [00:00,       ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Saving files                          0/4 [00:00<?,     ?file/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |.87pwm7wFFH2XC5gZWfEAyJ.tmp    0.00/17.6k [00:00<?,       ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |.R2yyduqujm2tFfC7MYDRJ8.tmp     0.00/165k [00:00<?,       ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |.ECYChNAkaFUd3CaG3EqdZN.tmp    0.00/3.83M [00:00<?,       ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |.2fmkXZPCpWXZvQq42XaRnQ.tmp    0.00/2.72k [00:00<?,       ?it/s]\u001b[A\n",
      "100% Add|██████████████████████████████████████████████|1/1 [00:00,  1.90file/s]\u001b[A\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add initial_model.dvc\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc add initial_model/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "39c11905",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add initial_model.dvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "47af0028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\r\n",
      "Your branch is ahead of 'origin/master' by 1 commit.\r\n",
      "  (use \"git push\" to publish your local commits)\r\n",
      "\r\n",
      "Changes to be committed:\r\n",
      "  (use \"git reset HEAD <file>...\" to unstage)\r\n",
      "\r\n",
      "\t\u001b[32mmodified:   initial_model.dvc\u001b[m\r\n",
      "\r\n",
      "Changes not staged for commit:\r\n",
      "  (use \"git add <file>...\" to update what will be committed)\r\n",
      "  (use \"git checkout -- <file>...\" to discard changes in working directory)\r\n",
      "\r\n",
      "\t\u001b[31mmodified:   FinalProj2_production.ipynb\u001b[m\r\n",
      "\r\n",
      "Untracked files:\r\n",
      "  (use \"git add <file>...\" to include in what will be committed)\r\n",
      "\r\n",
      "\t\u001b[31m.ipynb_checkpoints/\u001b[m\r\n",
      "\t\u001b[31mUntitled.ipynb\u001b[m\r\n",
      "\t\u001b[31maccum_data/\u001b[m\r\n",
      "\t\u001b[31mmlruns/\u001b[m\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2421061b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add FinalProj2_Initial.ipynb FinalProj2_production.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7c943e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master fcd9e13] Model trained wit data at_1\r\n",
      " 2 files changed, 116 insertions(+), 48 deletions(-)\r\n"
     ]
    }
   ],
   "source": [
    "!git commit -m \"Model trained wit data at_1\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
